sdocp('sdoc::js::core/caterwaul.macroexpander', 'Macroexpansion.\nCaterwaul is a Lisp, which in this case means that it provides the ability to transform code before that code is compiled. Lisp does macroexpansion inline; that is, as the code is being read\n(or compiled -- there are several stages I believe). Caterwaul provides offline macros instead; that is, you define them separately from their use. This gives Caterwaul some opportunity to\noptimize macro-rewriting.\n\nDefining offline macros is done in the normal execution path. For example:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[let (_ = _) in _], fn[n, v, e][qs[fn[args][body].call(this, values)].replace({args: n, body: e, values: v})]);\n  }) ();        // Must invoke the function\n\n| // Macro is usable in this function:\n  caterwaul(function () {\n    let (x = 5) in console.log(x);\n  });\n\nWrapping the first function in caterwaul() wasn\'t necessary, though it was helpful to get the qs[] and fn[] shorthands. In this case, the macro is persistent to the caterwaul function that it\nwas called on. (So any future caterwaul()ed functions would have access to it.)\n\nYou can also define conditional macros, though they will probably be slower. For example:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[let (_) in _], fn[bs, e][bs.data === \'=\' && ...]);\n  }) ();\n\nHere, returning a falsy value indicates that nothing should be changed about this syntax tree. It is replaced by itself and processing continues normally. You should try to express things in\nterms of patterns; there are theoretical optimizations that can cut the average-case runtime of pattern matching to a fraction of a full linear scan. The worst possible case is when you match\non a universal pattern and restrict later:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[_], fn[x][...]);\n  }) ();\n\nThis will call your macroexpander once for every node in the syntax tree, which for large progams is costly. If you really do have such a variant structure, your best bet is to define separate\nmacros, one for each case:\n\n| caterwaul(function () {\n    var patterns = [qs[foo], qs[bar], qs[bif]];\n    patterns.map (function (p) {\n      caterwaul.rmacro (p, fn[x][...]);\n    });\n  }) ();\n\nThis gives Caterwaul the opportunity to call your function only on relevant nodes. (Note that at present I haven\'t found an algorithm to make things any faster than using a depth-first scan.\nHowever, if I do find such an algorithm later on then macroexpansion will run quite a bit faster for programs with well-defined patterns.)\n\n  Pitfalls of macroexpansion.\n  Macroexpansion as described here can encode a lambda-calculus. The whole point of having macros is to make them capable, so I can\'t complain about that. But there are limits to how far I\'m\n  willing to go down the pattern-matching path. Let\'s suppose the existence of the let-macro, for instance:\n\n  | let (x = y) in z   ->   (function (x) {return z}) (y)\n\n  If you write these macros:\n\n  | foo[x, y]   ->   let (x = y)\n    bar[x, y]   ->   x in y\n\n  Caterwaul is not required to expand bar[foo[x, y], z] into (function (x) {return z}) (y). It might just leave it at let (x = y) in z instead. The reason is that while the individual\n  macroexpansion outputs are macroexpanded, a fixed point is not run on macroexpansion in general. (That would require multiple-indexing, which in my opinion isn\'t worth the cost.) To get the\n  extra macroexpansion you would have to wrap the whole expression in another macro, in this case called \'expand\':\n\n  | caterwaul.configure(function () {\n      this.rmacro(expand[_], fn[expression][caterwaul.macroexpand(expression)]);\n    });\n\n  This is an eager macro; by outputting the already-expanded contents, it gets another free pass through the macroexpander.\n\n  Things that are not guaranteed:\n\n  | 1. Reassembly of different pieces (see above)\n    2. Anything at all, if you modify the syntax tree in the macro code. Returning a replacement is one thing, but modifying one will break things.\n    3. Performance bounds.\n\n  Matching.\n  macro_try_match returns null if two syntax trees don\'t match, or a possibly empty array of wildcards if the given tree matches the pattern. Wildcards are indicated by \'_\' nodes, as\n  illustrated in the macro definition examples earlier in this section. Note that this function is O(n) in the number of nodes in the pattern. It is optimized, though, to reject invalid nodes\n  quickly -- that is, if there is any mismatch in arity or data.\n\n  var macro_array_push = Array.prototype.push,\n      macro_try_match  = function (pattern, t) {if (pattern.data === \'_\')                                   return [t];\n                                                if (pattern.data !== t.data || pattern.length !== t.length) return null;\n                                                for (var i = 0, l = pattern.length, wildcards = [], match = null; i < l; ++i)\n                                                  if (match = macro_try_match(pattern[i], t[i])) macro_array_push.apply(wildcards, match);\n                                                  else                                           return null;\n                                                return wildcards},\n\n  Expansion.\n  Uses the straightforward brute-force algorithm to go through the source tree and expand macros. At first I tried to use indexes, but found that I couldn\'t think of a particularly good way to\n  avoid double-expansion -- that is, problems like qs[qs[foo]] -- the outer must be expanded without the inner one. Most indexing strategies would not reliably (or if reliably, not profitably)\n  index the tree in such a way as to encode containment. Perhaps at some point I\'ll find a faster macroexpander, especially if this one proves to be slow. At this point macroexpansion is by\n  far the most complex part of this system, at O(nki) where n is the number of parse tree nodes, k is the number of macros, and i is the number of nodes in the macro pattern tree. (Though in\n  practice it\'s generally not quite so bad.)\n  \n  Note! This function by default does not re-macroexpand the output of macros. That is handled at a higher level by Caterwaul\'s macro definition facility (see the \'rmacro\' method).\n\n  The fourth parameter, \'context\', is used to hand a \'this\' reference to the macroexpander. This is necessary to get defmacro[] to work properly, and in general lets macros be side-effectful.\n  (Not that you should be in the habit of defining side-effectful macros, but I certainly won\'t stop you.)\n\n  Note that as of version 0.5, macroexpansion proceeds backwards. This means that the /last/ matching macro is used, not the first. It\'s an important feature, as it lets you write new macros\n  to override previous definitions. This ultimately lets you define sub-caterwaul functions for DSLs, and each can define a default case by matching on qs[_] (thus preventing access to other\n  macro definitions that may exist).\n\n    macro_expand = function (t, macros, expanders, context) {\n                     return t.rmap(function (n) {for (var i = macros.length - 1, macro, match, replacement; i >= 0 && (macro = macros[i]); --i)\n                                                   if ((match = macro_try_match(macro, n)) && (replacement = expanders[i].apply(context, match))) return replacement})};');