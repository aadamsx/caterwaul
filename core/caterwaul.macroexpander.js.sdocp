sdocp('sdoc::js::core/caterwaul.macroexpander', 'Macroexpansion.\nCaterwaul is a Lisp, which in this case means that it provides the ability to transform code before that code is compiled. Lisp does macroexpansion inline; that is, as the code is being read\n(or compiled -- there are several stages I believe). Caterwaul provides offline macros instead; that is, you define them separately from their use. This gives Caterwaul some opportunity to\noptimize macro-rewriting.\n\nDefining offline macros is done in the normal execution path. For example:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[let (_ = _) in _], fn[n, v, e][qs[fn[args][body].call(this, values)].replace({args: n, body: e, values: v})]);\n  }) ();        // Must invoke the function\n\n| // Macro is usable in this function:\n  caterwaul(function () {\n    let (x = 5) in console.log(x);\n  });\n\nWrapping the first function in caterwaul() wasn\'t necessary, though it was helpful to get the qs[] and fn[] shorthands. In this case, the macro is persistent to the caterwaul function that it\nwas called on. (So any future caterwaul()ed functions would have access to it.) You can also define conditional macros, though they will probably be slower. For example:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[let (_) in _], fn[bs, e][bs.data === \'=\' && ...]);\n  }) ();\n\nHere, returning a falsy value indicates that nothing should be changed about this syntax tree. It is replaced by itself and processing continues normally. You should try to express things in\nterms of patterns; there are theoretical optimizations that can cut the average-case runtime of pattern matching to a fraction of a full linear scan. The worst possible case is when you match\non a universal pattern and restrict later:\n\n| caterwaul(function () {\n    caterwaul.rmacro(qs[_], fn[x][...]);\n  }) ();\n\nThis will call your macroexpander once for every node in the syntax tree, which for large progams is costly. If you really do have such a variant structure, your best bet is to define separate\nmacros, one for each case:\n\n| caterwaul(function () {\n    var patterns = [qs[foo], qs[bar], qs[bif]];\n    patterns.map (function (p) {\n      caterwaul.rmacro(p, fn[x][...]);\n    });\n  }) ();\n\nCaterwaul implements several optimizations that make it much faster to macroexpand code when the macro patterns are easily identified.\n\n  Pitfalls of macroexpansion.\n  Macroexpansion as described here can encode a lambda-calculus. The whole point of having macros is to make them capable, so I can\'t complain about that. But there are limits to how far I\'m\n  willing to go down the pattern-matching path. Let\'s suppose the existence of the let-macro, for instance:\n\n  | let (x = y) in z   ->   (function (x) {return z}) (y)\n\n  If you write these macros:\n\n  | foo[x, y]   ->   let (x = y)\n    bar[x, y]   ->   x in y\n\n  Caterwaul is not required to expand bar[foo[x, y], z] into (function (x) {return z}) (y). It might just leave it at let (x = y) in z instead. The reason is that while the individual\n  macroexpansion outputs are macroexpanded, a fixed point is not run on macroexpansion in general. (That would require multiple-indexing, which in my opinion isn\'t worth the cost.) To get the\n  extra macroexpansion you would have to wrap the whole expression in another macro, in this case called \'expand\':\n\n  | caterwaul.configure(function () {\n      this.rmacro(expand[_], fn[expression][caterwaul.macroexpand(expression)]);\n    });\n\n  This is an eager macro; by outputting the already-expanded contents, it gets another free pass through the macroexpander.\n\n  Things that are not guaranteed:\n\n  | 1. Reassembly of different pieces (see above).\n    2. Anything at all, if you modify the syntax tree in the macro code. Returning a replacement is one thing, but modifying one will break things.\n    3. Performance bounds.\n\n- pinclude pp::js::core/caterwaul.macroexpander.naive\n- pinclude pp::js::core/caterwaul.macroexpander.jit');