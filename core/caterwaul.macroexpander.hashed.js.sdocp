sdocp('sdoc::js::core/caterwaul.macroexpander.hashed', 'Hashed macroexpander.\nThe naive macroexpander, implemented in sdoc::js::core/caterwaul.macroexpander.naive, takes linear time both in the number of syntax nodes and the number of macros. For potentially deep\npattern trees this becomes too slow for regular use. This macroexpander uses adaptive hashing to optimize lookups against the macro table, eliminating most of the checks that would have\nfailed.\n\n  Algorithm and use case analysis.\n  For n syntax nodes and k macro patterns, a naive approach performs O(nk) tree-match operations. Each match is O(n) in the complexity of the pattern tree. At first it seemed like this would\n  scale reasonably well, but version 0.6.7 of Caterwaul performed 750000 tree-match operations to load just the standard libraries. This ended up taking several seconds on some runtimes.\n\n  Hashing is an attractive solution because of the way macros are usually structured. It\'s unfortunate that the space of operator nodes is limited, but several different hashes in combination\n  can reduce the pattern space considerably. For example, here are some of the patterns used by the standard library:\n\n  | (* (l) ([] ([ (_)) (_)))\n    (* (let) ([] ([ (_)) (_)))\n    (, (_) (* (where) ([ (_))))\n    (, (_) ([] (unless) (_)))\n    (, (_) ([] (when) (_)))\n    (, (_) ([] (where) (_)))\n    (/ (/ (_) (mb)) (_))\n    (/ (_) ([] (. (cpb) (_)) (_)))\n    (/ (_) ([] (. (cps) (_)) (_)))\n    (/ (_) ([] (. (re) (_)) (_)))\n    (/ (_) ([] (. (se) (_)) (_)))\n\n  Just partitioning on the top node can save on average between 1/2 and 1/3 of the macro lookups. It\'s possible to do better though. An alternative strategy is to dive into the tree until we\n  hit a non-wildcard identifier and record its path. For example:\n\n  | (* (l) ([] ([ (_)) (_)))            -> l, [0]\n    (* (let) ([] ([ (_)) (_)))          -> let, [0]\n    (, (_) (* (where) ([ (_))))         -> where, [1][0]\n    (, (_) ([] (unless) (_)))           -> unless, [1][0]\n    (, (_) ([] (when) (_)))             -> when, [1][0]\n    (, (_) ([] (where) (_)))            -> where, [1][0]\n    (/ (/ (_) (mb)) (_))                -> mb, [0][1]\n    (/ (_) ([] (. (cpb) (_)) (_)))      -> cpb, [1][0][0]\n    (/ (_) ([] (. (cps) (_)) (_)))      -> cps, [1][0][0]\n    (/ (_) ([] (. (re) (_)) (_)))       -> re, [1][0][0]\n    (/ (_) ([] (. (se) (_)) (_)))       -> se, [1][0][0]\n\n  Note that we can\'t apply the same transformation to actual syntax nodes (since they may have identifiers all over the place), but that\'s ok. Each element in the table has a cost of\n  computation (more node traversal costs more), and it has a certain discrimination benefit (it reduces the number of comparisons we\'ll have to do later). Implicit in the discrimination\n  benefit is also the fact that deeper identifier embedding in the pattern indicates a pattern that is more difficult to reject quickly. This follows because there are many more identifiers\n  than operators, so statistically we expect to reject more patterns based on failed identifier matches than failed operator matches.');